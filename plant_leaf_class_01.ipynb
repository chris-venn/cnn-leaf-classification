{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python code for plant leaf image classification using different algorithms (Naive Gaussian Bayes, Logistic Regression, Decision Tree, Random Forest, k-Nearest Neighbors) on the Leafsnap Dataset from http://leafsnap.com/dataset/. The code is based on https://gogul09.github.io/software/image-classification-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import mahotas\n",
    "import h5py\n",
    "import glob\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility and data path to image folders.\n",
    "\n",
    "seed = 2\n",
    "data_path_field = 'C:/images/field/'\n",
    "data_path_lab = 'C:/images/lab/'\n",
    "train_labels = os.listdir(data_path_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hu-Moments to capture shape.\n",
    "\n",
    "def fd_hu_moments(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    feature = cv2.HuMoments(cv2.moments(image)).flatten()\n",
    "    \n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haralick features to capture texture.\n",
    "\n",
    "def fd_haralick(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    haralick = mahotas.features.haralick(gray).mean(axis=0)\n",
    "    \n",
    "    return haralick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color histogram to capture color.\n",
    "\n",
    "def fd_histogram(image, mask=None):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist  = cv2.calcHist([image], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "    cv2.normalize(hist, hist)\n",
    "\n",
    "    return hist.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "labels = []\n",
    "features = []\n",
    "\n",
    "# Iterate through every image in every folder.\n",
    "for training_name in train_labels:\n",
    "    current_label = training_name\n",
    "\n",
    "    for file in glob.glob(os.path.join(data_path_lab + str(current_label) + '/', '*.jpg')):\n",
    "        \n",
    "        # Read and resize every image.\n",
    "        image = cv2.imread(file)\n",
    "        image = cv2.resize(image, (64, 64))\n",
    "        \n",
    "        # Extract shape, texture and color values.\n",
    "        hu = fd_hu_moments(image)\n",
    "        haralick = fd_haralick(image)\n",
    "        histogram = fd_histogram(image)\n",
    "        \n",
    "        # Concatenate the extracted values and store them in the features list.\n",
    "        feature = np.hstack([hu, haralick, histogram])\n",
    "        features.append(feature)\n",
    "        labels.append(current_label)\n",
    "        \n",
    "    print('*Folder -lab- ' + str(current_label) + ' has been processed.')\n",
    "\n",
    "    for file in glob.glob(os.path.join(data_path_field + str(current_label) + '/', '*.jpg')):\n",
    "        \n",
    "         # Read and resize every image.\n",
    "        image = cv2.imread(file)\n",
    "        image = cv2.resize(image, (64, 64))\n",
    "        \n",
    "        # Extract shape, texture and color values.\n",
    "        hu = fd_hu_moments(image)\n",
    "        haralick = fd_haralick(image)\n",
    "        histogram = fd_histogram(image)\n",
    "        \n",
    "        # Concatenate the extracted values and store them in the features list.\n",
    "        feature = np.hstack([hu, haralick, histogram])\n",
    "        features.append(feature)\n",
    "        labels.append(current_label)\n",
    "        \n",
    "    # Keep track while processing.\n",
    "    print('*Folder -field- ' + str(current_label) + ' has been processed.')\n",
    "print('*ALL FOLDERS PROCESSED.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print('Feature vector size is {}'.format(np.array(features).shape))\n",
    "print('Labels vector size is {}'.format(np.array(labels).shape))\n",
    "\n",
    "\n",
    "# Transform label names to integers.\n",
    "label_names = np.unique(labels)\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(labels)\n",
    "\n",
    "# Check if transformation was successful.\n",
    "print ('Labels are {}'.format(label))\n",
    "\n",
    "# Normalize feature values between 0 and 1.\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "normalized_features = scaler.fit_transform(features)\n",
    "\n",
    "# Write h5py files with feature values and labels.\n",
    "h5_data = h5py.File('output_data.h5', 'w')\n",
    "h5_data.create_dataset('dataset_1', data=np.array(normalized_features))\n",
    "\n",
    "h5_label = h5py.File('output_labels.h5', 'w')\n",
    "h5_label.create_dataset('dataset_1', data=np.array(label))\n",
    "\n",
    "h5_data.close()\n",
    "h5_label.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list with Classifier Algorithms.\n",
    "\n",
    "models = []\n",
    "models.append(('Naive Gaussian Bayes', GaussianNB()))\n",
    "models.append(('Logistic Regression', LogisticRegression(random_state=seed)))\n",
    "models.append(('Decision Tree', DecisionTreeClassifier(random_state=seed)))\n",
    "models.append(('Random Forest', RandomForestClassifier(n_estimators=100, random_state=seed)))\n",
    "models.append(('KNN', KNeighborsClassifier(n_neighbors=6)))\n",
    "\n",
    "# Read h5py files and store data in feature_values and label_values respectively.\n",
    "h5_data = h5py.File('output_data.h5', 'r')\n",
    "h5_label = h5py.File('output_labels.h5', 'r')\n",
    "\n",
    "features_string = h5_data['dataset_1']\n",
    "labels_string = h5_label['dataset_1']\n",
    "\n",
    "feature_values = np.array(features_string)\n",
    "label_values = np.array(labels_string)\n",
    "\n",
    "h5_data.close()\n",
    "h5_label.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data in training and testing sets.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_values, label_values,\n",
    "                                                    test_size=0.2, random_state=seed)\n",
    "print('Data splitted in:')\n",
    "print('Training data: {}'.format(X_train.shape))\n",
    "print('Training labels: {}'.format(y_train.shape))\n",
    "print('Testing data: {}'.format(X_test.shape))\n",
    "print('Testing labels: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cv_results_list = []\n",
    "names = []\n",
    "\n",
    "# Train every model by 3-fold cross validation and store each accuracy score.\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=3, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    cv_results_list.append(cv_results)\n",
    "    names.append(name)\n",
    "    print('Cross validation of ' + str(name) + ' algorithm done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean and standard deviation of the three scores for each model and \n",
    "# print the final output.\n",
    "\n",
    "list_mean = []\n",
    "list_std = []\n",
    "for model in cv_results_list:\n",
    "    classifier_mean = model.mean()\n",
    "    classifier_std = model.std()\n",
    "    list_mean.append(classifier_mean)\n",
    "    list_std.append(classifier_std)\n",
    "final_list = pd.DataFrame(list(zip(names, list_mean, list_std)), \n",
    "                          columns=['model', 'score', 'standard deviation'], index = [1,2,3,4,5])\n",
    "print(final_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize final output as boxplot. \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.suptitle('Accuracy Comparison of Classifier Algorithms')\n",
    "plt.boxplot(cv_results_list)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0,1])\n",
    "plt.xticks([1,2,3,4,5],final_list['model'], fontsize=7, rotation=40)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
